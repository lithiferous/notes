{
  "metadata": {
    "name": "spark_pair_rdds",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n### Creating a Pair RDD"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval pairs \u003d lines.map(x \u003d\u003e x.split(\" \")(0), x)\nval ppairs \u003d sc.parallelize(pairs)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Transforms on a Pair RDDs\nexample: {(1, 2), (3, 4), (3,6)}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**reduceByKey**\n\nrdd.reduceByKey((x,y)\u003d\u003ex+y)\n*{(1, 2),(3, 10))}*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**groupByKey**\n\nrdd.groupByKey\n*{(1, [2]), (3, [4, 6])}*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**mapValues(func)**\nrdd.flatMapValues(x \u003d\u003e (x to 5))\n*{(1,2), (1,3), (1,4), (1,5), (3,4), (3,5)}*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**combineByKey(createCombiner, mergeValue, mergeCombiners, partitioner)**\n\nval result \u003d in.combineByKey(\n    (v) \u003d\u003e (v, 1),\n    (acc: (Int, Int), v) \u003d\u003e (acc._1 + v, acc._2 + 1),\n    (acc1: (Int, Int), acc2: (Int, Int)) \u003d\u003e (acc1._1 + acc2._1, acc1._2 + acc2._2),\n    ).map{ case (key, value) \u003d\u003e (key, value._1/value._2.toFloat)}\nresult.collectAsMap().map(println(_))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**Keys \u0026 Values**"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**sortByKey**"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Transform on two pair RDDs\nrdd \u003d {(1,2),(3,4), (3,6)} other \u003d {(3, 9)}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**subtractByKey**\nrdd.subtractByKey(other)\n*res \u003d {(1,2)}*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**join**\nrdd.join(other)\n*res \u003d {(3,[4, 9]), (3, [6, 9])}*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**rightOuterJoin**\nrdd.rightOuterJoin(other)\n*res \u003d {(3, (Some(4),9)), (3, (Some(6), 9)) }*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**leftOuterJoin**\nrdd.leftOuterJoin(other)\n*res \u003d {(1, (2, None)), (3, (4,Some(9))), (3, (6, Some(9))) }*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**cogroup**\nrdd.cogroup(other)\n*res \u003d {(1, [2],[]), (3, ([4, 6], 9)}*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Functions\n**filter**\nrdd.filter{case (key, value) \u003d\u003e value.length \u003c 20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**better filter**\nrdd.mapValues{x \u003d\u003e x.length \u003c 20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Aggregations\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### *Per-key avg with reduceByKey and mapValues*\nrdd.mapValues(x \u003d\u003e x, 1).reduceByKey((x,y) \u003d\u003e (x._1 + y._1, x._2 + y._2))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### *word count and count words*\nval in \u003d sc.paralleliz(\"s3:?//\")\nval words \u003d in.flatMap(x \u003d\u003e x.split(\" \"))\nval res \u003d words.map(x \u003d\u003e x,1).reducByKey((x, y)\u003d\u003ex+y)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Grouping"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**groupByKey** *will group our data with supplied key , we get back RDD[Key, Iterable[Vals]*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Example sort"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval storeAddr \u003d sc.parallelize(Array(\n    (3, \"3101 24th St\"),\n    (4, \"23 Seattle\"),\n    (1, \"1026 Valencia St\"),\n    (2, \"748 Van Ness Ave\"))\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimplicit val sortIntegersByString \u003d new Ordering[Int] {\n    override def compare(a: Int, b: Int) \u003d a.toString.compare(b.toString)\n}\nstoreAddr.sortByKey().collect.take(4)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Actions\nrdd \u003d {(1,2),(3,4), (3,6)} other \u003d {(3, 9)}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "rdd.countByKey()\n*res \u003d {(1, 1), (3, 2}}*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "rdd.collectAsMap()\n*res \u003d Map{(1,2), (3,4), (3,6)}*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "rdd.lookup(3)\n*res \u003d [4,6]*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    }
  ]
}